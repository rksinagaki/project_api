{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01eb8c69-a0c7-4fd4-9924-a54aa64b0291",
   "metadata": {},
   "source": [
    "# マルチモーダル　RAG チャットボットの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4c58ed-af3c-446c-b0b7-f8c9111420e0",
   "metadata": {},
   "source": [
    "## 以下の順でlangchain実装練習\n",
    "1. ユーザインタフェースの実装\n",
    "2. 質問応答システムの拡張\n",
    "3. 会話履歴の実装\n",
    "4. コンテキストの拡張\n",
    "5. RAGの実装\n",
    "6. マルチモーダル対応"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f48b7eb-2f4b-42de-aad9-a86b3c8eef23",
   "metadata": {},
   "source": [
    "## 1. ユーザインタフェースの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34c8d5ee-ce65-453a-87fc-8ba48b92a725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 02:18:38.614 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.615 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.615 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.616 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.617 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.617 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.619 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.619 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.620 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.621 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.622 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.622 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.623 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.623 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.624 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.625 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.625 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.625 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.626 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.626 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.627 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-11 02:18:38.627 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "st.title(\"マルチモーダルRAGチャットボット\")\n",
    "\n",
    "# アップローダを追加\n",
    "uploaded_file = st.file_uploader(\"画像を選択してください\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "# アップロードされた画像を表示\n",
    "if uploaded_file is not None:\n",
    "    st.image(uploaded_file, caption=\"画像\", widch=300)\n",
    "\n",
    "# ユーザ入力を受け取る\n",
    "user_input = st.text_input(\"メッセージを入力してください:\") \n",
    "\n",
    "#　ボタンを追加し、クリックしたらアクションを起こす\n",
    "if st.button(\"送信\"):\n",
    "#　入力されたテキストを表示\n",
    "    st.write(f\"human: {user_input}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37511f91-85b9-440f-8361-b32ca7154018",
   "metadata": {},
   "source": [
    "## 2. 質問応答システムへの拡張"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb589244-d52f-4891-9b82-b9215ad7b572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=api_key,   # ←ここでキーを渡す\n",
    "    )\n",
    "\n",
    "response = llm.invoke(user_input)\n",
    "    # 会話を表示\n",
    "st.write(f\"ai: {response.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15ac4273-9208-42cf-8437-56db54da2bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+1は**2**です。\n"
     ]
    }
   ],
   "source": [
    "# 接続テスト\n",
    "print(llm.invoke(\"1+1は？\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80750631-6a99-409b-8bf9-cfa74ac9231d",
   "metadata": {},
   "source": [
    "## 3. 会話履歴の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857de08c-c3a2-4d0c-9468-9445df1b6b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "# セッション状態を初期化\n",
    "if \"history\" not in st.session_state:\n",
    "    st.session_state.history = []\n",
    "    st.session_state.llm = ChatGoogleGenerativeAI()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d902f0-975a-4097-87b3-346a96a5d705",
   "metadata": {},
   "source": [
    "- Streamlitは“実行がリロード型”、継続したい情報はst.session_stateに置く必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dbc10e-8a23-4998-a896-aa23ff74d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ボタンを追加してクリックされたらアクションを起こす\n",
    "if st.button(\"送信\"):\n",
    "    st.session_state.history.append(HumanMessage(user_input))\n",
    "    response = st.session_state.llm.invoke(st.session_state.history)\n",
    "    st.session_state.history.append(response)    \n",
    "\n",
    "    # 会話を表示\n",
    "    for message in reversed(st.session_state.history):\n",
    "        st.write(f\"{message.type}: {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab79894d-7edb-491a-9e26-df9ff91a8b07",
   "metadata": {},
   "source": [
    "- 会話がAIと人間で交互にhistoryに保存されるようになる\n",
    "- それを逆順で表示（新しいのが最新一番上にくる）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cc52af-f639-4c06-bb00-1b27197f2012",
   "metadata": {},
   "source": [
    "## 4. コンテキストの拡張"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "398c9195-990c-4e8f-8838-c87ba55be7df",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_core'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_core'"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8bc117-7e55-4a2d-8b8e-54e69c5e19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# チェーンを作成\n",
    "def create_chain():\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"回答には以下の情報も参考にしてください。参考情報：\\n{info}\",\n",
    "            ),\n",
    "            (\"placeholder\", \"{history}\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    return prompt | ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", google_api_key=api_key)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfcfeb5-3209-4425-999e-745abb04e51f",
   "metadata": {},
   "source": [
    "- プロンプトテンプレートで入力データを整形してから、モデルに渡して応答を得る\n",
    "\n",
    "- 左の prompt：入力（info, history, input など）を受け取り→ LLMが読めるメッセージ形式に変換\n",
    "- 右の ChatGoogleGenerativeAI：それを受け取って→ 実際にAPIで生成処理（推論）を行う\n",
    "\n",
    "- placeholderは過去の会話履歴そのまま挿入するよってイメージ？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645cca8b-f591-4ea1-90c8-b2933c121ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# クリック時のアクションを変更してみる\n",
    "response = st.session_state.chain.invoke(\n",
    "    {\n",
    "        \"input\":user_input,\n",
    "        \"history\":st.session_state.history,\n",
    "        \"info\":\"ユーザの年齢は10歳です\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e885e98f-2325-430e-a98b-96b0b1d30c65",
   "metadata": {},
   "source": [
    "## 5. RAGの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b9c7df-83b8-4416-9afb-b9f514867a66",
   "metadata": {},
   "source": [
    "## インデックスを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fc38b6-cf6a-4af9-8ce9-44c028cc988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3965b5ed-9063-4e97-a36c-6857204aba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(filename):\n",
    "    # CSVをロード\n",
    "    loader = CSVLoader(file_path=filename, autodetect_encoding=True)\n",
    "    pages = loader.load()\n",
    "\n",
    "    # テキストを分割\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=400)\n",
    "    splits = text_splitter.split_documents(pages)\n",
    "\n",
    "    # 埋め込みモデルを定義（Gemini埋め込み）\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "    # Chromaベクトルストアを作成・保存\n",
    "    db = Chroma.from_documents(\n",
    "        documents=splits,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=\"data/hino_trash\"  # ベクトルデータを保存する場所\n",
    "    )\n",
    "    print(\"インデックス作成完了\")\n",
    "\n",
    "# ← ここから下がスクリプト直実行時の入り口\n",
    "if __name__ == \"__main__\":\n",
    "    # ここでCSVの場所を指定（相対パス or 絶対パス）\n",
    "    csv_path = \"../../data/hino_trash/hino_trash.csv\"   # ← 自分のファイル名に合わせて変更\n",
    "    load_document(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3273d0-e049-42c1-bff4-94b2e213880c",
   "metadata": {},
   "source": [
    "### 一度だけ実行してインデックス作成すれば良い\n",
    "- docker exec -it project_api-streamlit bash\n",
    "- cd /work/src/app\n",
    "- python make_index.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e298bd2-369b-4edc-9a77-42d9b6188178",
   "metadata": {},
   "source": [
    "### これでようやくできた"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252bf028-a90c-4d57-80d9-acb7f9f1f6d4",
   "metadata": {},
   "source": [
    "### インデックスの利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc284428-a229-49da-945f-062fb562eec5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_chroma'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_chroma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GoogleGenerativeAIEmbeddings\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moperator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m itemgetter\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_chroma'"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b99818b-0113-4c9b-91b9-5b555117e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ドキュメントを整形\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f04628b5-3741-467b-9acf-41c6a45f08b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chain():\n",
    "    vectorstore = Chroma(\n",
    "        embedding_function=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"),\n",
    "        persist_directory=\"data/hino_trash\",\n",
    "    )\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1461b7-0527-4f1d-9c05-d8e74aa50283",
   "metadata": {},
   "outputs": [],
   "source": [
    "    return(\n",
    "        {\n",
    "            \"input\": itemgetter(\"input\"),\n",
    "            \"info\": itemgetter(\"input\") | retriever | format_docs,\n",
    "            \"history\": itemgetter(\"history\"),\n",
    "        }\n",
    "        | prompt \n",
    "        | ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", google_api_key=api_key, temperature=0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029fedef-7e45-4d3d-9c43-5d2fb2fb4495",
   "metadata": {},
   "source": [
    "## 6. マルチモーダル対応"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ad93b5-bb4b-4753-8cb9-626f6f2708cb",
   "metadata": {},
   "source": [
    "### 画像とテキストで検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8fbc03-f769-40a7-8881-5df611d8450f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
